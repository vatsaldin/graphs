{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Building a Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Remark<div class='tocSkip'/>\n",
    "\n",
    "The code in this notebook differs slightly from the printed book. For example we frequently use pretty print (`pp.pprint`) instead of `print` and `tqdm`'s `progress_apply` instead of Pandas' `apply`. \n",
    "\n",
    "Moreover, several layout and formatting commands, like `figsize` to control figure size or subplot commands are removed in the book.\n",
    "\n",
    "You may also find some lines marked with three hashes ###. Those are not in the book as well as they don't contribute to the concept.\n",
    "\n",
    "All of this is done to simplify the code in the book and put the focus on the important parts instead of formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## What you'll learn and what we build\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Knowledge Graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blueprint to Query Wikidata for Aliases not in Book\n",
    "\n",
    "Below you find an example of what you can do with public ontologies like Wikidata. Here, we defined a SPARQL query to retrieve the names, aliases and URLs of all entities of type \"United States federal executive department\" (https://www.wikidata.org/wiki/Q910252)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pip install sparqlwrapper\n",
    "# https://rdflib.github.io/sparqlwrapper/\n",
    "import pandas as pd\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from blueprints.knowledge import display_ner, reset_pipeline, print_dep_tree, alias_lookup\n",
    "import nltk\n",
    "#nltk.download('reuters')\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f4ea841a250>)\n",
      "('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f4ea84e1c20>)\n",
      "('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f4ebc6bead0>)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy\n",
    "print(*nlp.pipeline, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vatsal/Applications/miniconda3/envs/bertopic/lib/python3.7/site-packages/ipykernel_launcher.py:41: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "/home/vatsal/Applications/miniconda3/envs/bertopic/lib/python3.7/site-packages/ipykernel_launcher.py:42: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_id</th>\n",
       "      <th>org</th>\n",
       "      <th>aliases</th>\n",
       "      <th>url</th>\n",
       "      <th>country_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q501542</td>\n",
       "      <td>United States Department of Agriculture</td>\n",
       "      <td>[Department of Agriculture, USDA, U.S. Departm...</td>\n",
       "      <td>https://www.usda.gov/</td>\n",
       "      <td>Q30</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q503577</td>\n",
       "      <td>United States Department of Commerce</td>\n",
       "      <td>[DOC, Commerce, Department of Commerce, Commer...</td>\n",
       "      <td>https://www.commerce.gov/</td>\n",
       "      <td>Q30</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q861556</td>\n",
       "      <td>United States Department of Education</td>\n",
       "      <td>[ED, Department of Education, Dept. of Ed., Do...</td>\n",
       "      <td>https://www.ed.gov/</td>\n",
       "      <td>Q30</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q217810</td>\n",
       "      <td>United States Department of Energy</td>\n",
       "      <td>[Department of Energy, DOE, US Department of E...</td>\n",
       "      <td>https://www.energy.gov/</td>\n",
       "      <td>Q30</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q942326</td>\n",
       "      <td>United States Department of Health and Human S...</td>\n",
       "      <td>[HHS, Department of Health and Human Services,...</td>\n",
       "      <td>https://www.hhs.gov/</td>\n",
       "      <td>Q30</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q11231</td>\n",
       "      <td>United States Department of Homeland Security</td>\n",
       "      <td>[Department of Homeland Security, DHS, Homelan...</td>\n",
       "      <td>https://www.dhs.gov/</td>\n",
       "      <td>Q30</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q811595</td>\n",
       "      <td>United States Department of Housing and Urban ...</td>\n",
       "      <td>[HUD, Department of Housing and Urban Developm...</td>\n",
       "      <td>https://www.hud.gov/</td>\n",
       "      <td>Q30</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q1553390</td>\n",
       "      <td>United States Department of Justice</td>\n",
       "      <td>[Department of Justice, DOJ, Justice Departmen...</td>\n",
       "      <td>https://www.justice.gov/</td>\n",
       "      <td>Q30</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q628807</td>\n",
       "      <td>United States Department of Labor</td>\n",
       "      <td>[DOL, Department of Labor, U.S. Department of ...</td>\n",
       "      <td>https://www.dol.gov/</td>\n",
       "      <td>Q30</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q789915</td>\n",
       "      <td>United States Department of State</td>\n",
       "      <td>[DoS, State Department, U.S. Department of Sta...</td>\n",
       "      <td>https://www.state.gov/</td>\n",
       "      <td>Q30</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     org_id                                                org  \\\n",
       "0   Q501542            United States Department of Agriculture   \n",
       "1   Q503577               United States Department of Commerce   \n",
       "2   Q861556              United States Department of Education   \n",
       "3   Q217810                 United States Department of Energy   \n",
       "4   Q942326  United States Department of Health and Human S...   \n",
       "5    Q11231      United States Department of Homeland Security   \n",
       "6   Q811595  United States Department of Housing and Urban ...   \n",
       "7  Q1553390                United States Department of Justice   \n",
       "8   Q628807                  United States Department of Labor   \n",
       "9   Q789915                  United States Department of State   \n",
       "\n",
       "                                             aliases  \\\n",
       "0  [Department of Agriculture, USDA, U.S. Departm...   \n",
       "1  [DOC, Commerce, Department of Commerce, Commer...   \n",
       "2  [ED, Department of Education, Dept. of Ed., Do...   \n",
       "3  [Department of Energy, DOE, US Department of E...   \n",
       "4  [HHS, Department of Health and Human Services,...   \n",
       "5  [Department of Homeland Security, DHS, Homelan...   \n",
       "6  [HUD, Department of Housing and Urban Developm...   \n",
       "7  [Department of Justice, DOJ, Justice Departmen...   \n",
       "8  [DOL, Department of Labor, U.S. Department of ...   \n",
       "9  [DoS, State Department, U.S. Department of Sta...   \n",
       "\n",
       "                         url country_id                   country  \n",
       "0      https://www.usda.gov/        Q30  United States of America  \n",
       "1  https://www.commerce.gov/        Q30  United States of America  \n",
       "2        https://www.ed.gov/        Q30  United States of America  \n",
       "3    https://www.energy.gov/        Q30  United States of America  \n",
       "4       https://www.hhs.gov/        Q30  United States of America  \n",
       "5       https://www.dhs.gov/        Q30  United States of America  \n",
       "6       https://www.hud.gov/        Q30  United States of America  \n",
       "7   https://www.justice.gov/        Q30  United States of America  \n",
       "8       https://www.dol.gov/        Q30  United States of America  \n",
       "9     https://www.state.gov/        Q30  United States of America  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ?org ?orgLabel ?aliases ?urlLabel ?country ?countryLabel WITH {\n",
    "  SELECT ?org (group_concat(distinct ?alias;separator=\",\") as ?aliases)\n",
    "  WHERE {\n",
    "    ?org wdt:P31 wd:Q910252. # org is(P31) US department (Q910252)\n",
    "    ?org skos:altLabel ?alias. filter(lang(?alias)=\"en\")\n",
    "  } GROUP BY ?org } AS %i\n",
    "  WHERE {\n",
    "  include %i\n",
    "  ?org wdt:P856 ?url; # has official website (P856)\n",
    "       wdt:P17 ?country. # has country (P17)\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "}\n",
    "ORDER BY ?orgLabel\n",
    "\"\"\"\n",
    "\n",
    "def sparql_df(endpoint_url, query):\n",
    "    user_agent = \"Wikidata-Service Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    columns = results['head']['vars']\n",
    "    rows = []\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        row = {}\n",
    "        for col in result:\n",
    "            row[col] = result[col]['value']\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame.from_records(rows, columns=columns)\n",
    "\n",
    "wd_df = sparql_df(endpoint_url, query)\n",
    "\n",
    "# rename columns\n",
    "wd_df.columns = ['org_id', 'org', 'aliases', 'url', 'country_id', 'country']\n",
    "\n",
    "wd_df['org_id'] = wd_df['org_id'].str.replace('http://www.wikidata.org/entity/', '')\n",
    "wd_df['country_id'] = wd_df['country_id'].str.replace('http://www.wikidata.org/entity/', '')\n",
    "wd_df['aliases'] = wd_df['aliases'].str.split(',')\n",
    "\n",
    "wd_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building a Knowledge Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introducing the Data Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Preparation of NLTK Reuters Corpus (not in book)\n",
    "\n",
    "This section contains the steps how to create the data frame for some of the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10788 documents\n",
      "90 categories:\n",
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', '...']\n",
      "\n",
      "      The Reuters-21578 benchmark corpus, ApteMod version\n",
      "\n",
      "This is a publically available version of the well-known Reuters-21578\n",
      "\"ApteMod\" corpus for text categorization.  It has been used in\n",
      "public\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "\n",
    "# List of documents\n",
    "documents = reuters.fileids()\n",
    "print(str(len(documents)) + \" documents\")\n",
    "print(str(len(reuters.categories())) + \" categories:\")\n",
    "print(reuters.categories()[:10] + ['...'])\n",
    "\n",
    "print(reuters.readme()[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Each article is stored as a separated file. The data files are identified by a file ID of the form \"train/1234\" or \"test/5678\". We first create a data frame with the `fileid` column and then load the raw text for each ID into a second column. Finally, as we don't care whether it's train or test, we just the number from the file ID and use it as the index of our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 2369/2369 [00:00<00:00, 14462.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>GUINNESS TO SELL RETAIL INTERESTS\\n  Guinness ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>FIRST BOSTON AFFILIATE TO ACQUIRE ALLEGHENY IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17810</th>\n",
       "      <td>ATCOR&amp;lt;ATCO.O&gt; SEEKS BUYERS FOR CONSUMER BUS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     raw\n",
       "12441  GUINNESS TO SELL RETAIL INTERESTS\\n  Guinness ...\n",
       "3061   FIRST BOSTON AFFILIATE TO ACQUIRE ALLEGHENY IN...\n",
       "17810  ATCOR&lt;ATCO.O> SEEKS BUYERS FOR CONSUMER BUS..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "\n",
    "# create fileid column\n",
    "df = pd.DataFrame(reuters.fileids(\"acq\"), columns=['fileid'])\n",
    "# load raw texts\n",
    "df['raw'] = df['fileid'].progress_map(lambda f: reuters.raw(f))\n",
    "# set index to numeric id\n",
    "df.index = df['fileid'].map(lambda f: int(f.split('/')[1]))\n",
    "df.index.name = None\n",
    "df = df.drop(columns=['fileid']).sort_index()\n",
    "\n",
    "df.sample(3, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we see from the example, we will still need some data cleaning before we can expect to get reasonably good results during named entity recognition. First, we separate headlines from the actual news text by splitting at the first newline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 2369/2369 [00:00<00:00, 38406.38it/s]\n"
     ]
    }
   ],
   "source": [
    "df[['headline', 'raw_text']] = df.progress_apply(lambda row: row['raw'].split('\\n', 1),\n",
    "                                        axis='columns', result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we use the adapted data cleaning blueprint from Chapter 4 for to remove some disturbing artifacts, substitute some abbreviations (like \"dlr\" for dollar) and repair some typos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean(text):\n",
    "    text = text.replace('&lt;','<') # html escape\n",
    "    text = re.sub(r'[<>]', '\"', text) # quotation marks instead of <>\n",
    "    text = re.sub(r'[ ]*\"[A-Z\\.]+\"', '', text) # drop stock symbols\n",
    "    text = re.sub(r'[ ]*\\([A-Z\\.]+\\)', '', text) # drop stock symbols\n",
    "    text = re.sub(r'\\bdlr(s?)\\b', r'dollar\\1', text, flags=re.I)\n",
    "    text = re.sub(r'\\bmln(s?)\\b', r'million\\1', text, flags=re.I)\n",
    "    text = re.sub(r'\\bpct\\b', r'%', text, flags=re.I)\n",
    "    # normalize INC to Inc\n",
    "    text = re.sub(r'\\b(Co|Corp|Inc|Plc|Ltd)\\b', lambda m: m.expand(r'\\1').capitalize(), text, flags=re.I)\n",
    "    text = re.sub(r'\"', r'', text) # quotation marks\n",
    "    text = re.sub(r'\\s+', ' ', text) # multiple whitespace by one\n",
    "    text = re.sub(r'acquisiton', 'acquisition', text) # typo\n",
    "    text = re.sub(r'Nippon bLife', 'Nippon Life', text) # typo\n",
    "    text = re.sub(r'COMSAT.COMSAT', 'COMSAT. COMSAT', text) # missing space at end of sentence\n",
    "    #text = re.sub(r'Audio/Video', 'Audio-Video', text) # missing space at end of sentence\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So let's have a look at the result of our data cleaning steps :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trafalgar House Plc said it has acquired the entire share capital of Capital Homes Inc of the U.S. For 20 million dollars in cash.\n",
      "\n",
      "Equiticorp Holdings Ltd now owns or has received acceptances representing 59.93 % of the issued ordinary share capital of Guinness Peat Group Plc , Equiticorp said in a statement.\n",
      "\n",
      "Computer Terminal Systems Inc said it has completed the sale of 200,000 shares of its common stock, and warrants to acquire an additional one million shares, to Sedio N.V. of Lugano, Switzerland for 50,000 dollars.\n",
      "\n",
      "North American Group Ltd said it has a definitive agreement to buy 100 % of Pioneer Business Group Inc of Atlanta.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# that's what the substitutions do\n",
    "texts = [\n",
    "\"\"\"Trafalgar House Plc &lt;TRAF.L> said it has\\n  acquired the entire share capital\n",
    "of &lt;Capital Homes Inc> of the\\n  U.S. For 20 mln dlrs in cash.\"\"\",\n",
    "\"\"\"Equiticorp Holdings Ltd &lt;EQUW.WE> now owns\\n  or has received acceptances\n",
    "representing 59.93 pct of the\\n  issued ordinary share capital of\n",
    "Guinness Peat Group Plc\\n  &lt;GNSP.L>, Equiticorp said in a statement.\"\"\",\n",
    "\"\"\"Computer Terminal Systems Inc said it has completed the sale of 200,000 shares\n",
    "of its common stock, and warrants to acquire an additional one mln shares,\n",
    "to \"Sedio N.V.\" of Lugano, Switzerland for 50,000 dlrs.\"\"\",\n",
    "\"\"\"North American Group Ltd said it has a definitive agreement\n",
    "to buy 100  pct of Pioneer Business Group Inc of Atlanta.\"\"\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    print(clean(text), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We apply it to the `raw_text` and create a new `text` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 2369/2369 [00:00<00:00, 8383.31it/s]\n",
      "progress-bar: 100%|██████████| 2369/2369 [00:00<00:00, 56983.38it/s]\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['raw_text'].progress_map(clean)\n",
    "df['headline'] = df['headline'].progress_map(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The newly created column `text` contains the cleaned articles. But we have one disturbing artifact left in the data: a few articles, like the second one in the sample above, consist only of capital letters. In fact, here the raw text is identical to the headlines. We finally drop those because named entity recognition will not yield useful results on such a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>SHV SAYS IT MAKING TENDER OFFER FOR UP TO 33 m...</td>\n",
       "      <td>\\n  SHV SAYS IT MAKING TENDER OFFER FOR UP TO ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>VIACOM SAID IT HAS NEW NATIONAL AMUSEMENTS, MC...</td>\n",
       "      <td>\\n  VIACOM SAID IT HAS NEW NATIONAL AMUSEMENTS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>PITTSTON AGREES TO ACQUIRE WTC INTERNATIONAL I...</td>\n",
       "      <td>\\n  PITTSTON AGREES TO ACQUIRE WTC INTERNATION...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              headline  \\\n",
       "298  SHV SAYS IT MAKING TENDER OFFER FOR UP TO 33 m...   \n",
       "383  VIACOM SAID IT HAS NEW NATIONAL AMUSEMENTS, MC...   \n",
       "398  PITTSTON AGREES TO ACQUIRE WTC INTERNATIONAL I...   \n",
       "\n",
       "                                              raw_text  \n",
       "298  \\n  SHV SAYS IT MAKING TENDER OFFER FOR UP TO ...  \n",
       "383  \\n  VIACOM SAID IT HAS NEW NATIONAL AMUSEMENTS...  \n",
       "398  \\n  PITTSTON AGREES TO ACQUIRE WTC INTERNATION...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will drop these articles with only capital letters\n",
    "df[df['raw_text'].map(lambda t: t.isupper())][['headline', 'raw_text']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# drop articles with only capital letters\n",
    "df = df[df['raw_text'].map(lambda t: not t.isupper())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5077</th>\n",
       "      <td>TONY LAMA TO BUY COULSON OF TEXAS Inc</td>\n",
       "      <td>Tony Lama Co Inc said it signed a letter of in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9844</th>\n",
       "      <td>ETHYL Corp UNITS COMPLETE ACQUISITON</td>\n",
       "      <td>Ethyl Corp said its subsidiaries completed the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11508</th>\n",
       "      <td>QUANTUM VENTURE UPS COMPUTER NETWORK STAKE</td>\n",
       "      <td>Computer Network Technology Corp said that Qua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         headline  \\\n",
       "5077        TONY LAMA TO BUY COULSON OF TEXAS Inc   \n",
       "9844         ETHYL Corp UNITS COMPLETE ACQUISITON   \n",
       "11508  QUANTUM VENTURE UPS COMPUTER NETWORK STAKE   \n",
       "\n",
       "                                                    text  \n",
       "5077   Tony Lama Co Inc said it signed a letter of in...  \n",
       "9844   Ethyl Corp said its subsidiaries completed the...  \n",
       "11508  Computer Network Technology Corp said that Qua...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is our clean data set\n",
    "df[['headline', 'text']].sample(3, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Book section continues ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Named-Entity Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T17:56:51.835862Z",
     "start_time": "2021-02-25T17:56:51.786381Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hughes Tool Co', 'ORG') ('W.A. Kistler', 'PERSON') ('Baker International Corp', 'ORG') ('Kistler', 'ORG') ('Baker', 'PERSON') ('Texas', 'GPE') ('Hughes', 'ORG')\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Hughes Tool Co Chairman W.A. Kistler said its merger with \n",
    "Baker International Corp was still under consideration.\n",
    "We hope to come soon to a mutual agreement, Kistler said.\n",
    "The directors of Baker filed a law suit in Texas to force Hughes \n",
    "to complete the merger.\"\"\"\n",
    "text = re.sub(r'\\s+', ' ', text).strip() ###\n",
    "doc = nlp(text)\n",
    "\n",
    "print(*[(e.text, e.label_) for e in doc.ents], sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T17:56:51.982257Z",
     "start_time": "2021-02-25T17:56:51.938019Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hughes Tool Co\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " Chairman \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    W.A. Kistler\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said its merger with \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Baker International Corp\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " was still under consideration. We hope to come soon to a mutual agreement, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kistler\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " said. The directors of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Baker\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " filed a law suit in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Texas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " to force \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hughes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to complete the merger.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blueprint: Rule-based Named-Entity Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T17:56:52.190628Z",
     "start_time": "2021-02-25T17:56:52.134791Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: core_web_sm, Language: en\n",
      "('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f4ea841a250>)\n",
      "('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f4ea84e1c20>)\n",
      "('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f4ebc6bead0>)\n"
     ]
    }
   ],
   "source": [
    "reset_pipeline(nlp, pipes=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T17:56:52.321838Z",
     "start_time": "2021-02-25T17:56:52.281818Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "departments = ['Justice', 'Transportation']\n",
    "patterns = [{\"label\": \"GOV\", \n",
    "             \"pattern\": [{\"TEXT\": \"U.S.\", \"OP\": \"?\"},\n",
    "                         {\"TEXT\": \"Department\"}, {\"TEXT\": \"of\"}, \n",
    "                         {\"TEXT\": {\"IN\": departments}, \"ENT_TYPE\": \"ORG\"}]},\n",
    "             {\"label\": \"GOV\", \n",
    "              \"pattern\": [{\"TEXT\": \"U.S.\", \"OP\": \"?\"},\n",
    "                          {\"TEXT\": {\"IN\": departments}, \"ENT_TYPE\": \"ORG\"},\n",
    "                          {\"TEXT\": \"Department\"}]},\n",
    "             {\"label\": \"GOV\",\n",
    "              \"pattern\": [{\"TEXT\": \"Securities\"}, {\"TEXT\": \"and\"},\n",
    "                          {\"TEXT\": \"Exchange\"}, {\"TEXT\": \"Commission\"}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T17:56:52.611785Z",
     "start_time": "2021-02-25T17:56:52.563140Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# not in book, but useful if you modify the rules\n",
    "if nlp.has_pipe('entity_ruler'):\n",
    "    nlp.remove_pipe('entity_ruler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T17:57:07.388387Z",
     "start_time": "2021-02-25T17:57:07.351428Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entity_ruler'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EntityRuler.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T17:57:16.413646Z",
     "start_time": "2021-02-25T17:57:16.368739Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "entity_ruler = EntityRuler(nlp, patterns=patterns, overwrite_ents=True)\n",
    "nlp.add_pipe(entity_ruler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Justice Department\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GOV</span>\n",
       "</mark>\n",
       " is an alias for the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.S. Department of Justice\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GOV</span>\n",
       "</mark>\n",
       ".</br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Department of Transportation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GOV</span>\n",
       "</mark>\n",
       " and the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Securities and Exchange Commission\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GOV</span>\n",
       "</mark>\n",
       "</br>are government organisations, but \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Sales Department\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is not.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"\"\"Justice Department is an alias for the U.S. Department of Justice.\n",
    "Department of Transportation and the Securities and Exchange Commission\n",
    "are government organisations, but the Sales Department is not.\"\"\"\n",
    "#text = re.sub(r'\\s+', ' ', text).strip() ###\n",
    "\n",
    "doc = nlp(text)\n",
    "# print(*[([t.text for t in e], e.label_) for e in doc.ents], sep='\\n') ###\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blueprint: Normalizing Named-Entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: core_web_sm, Language: en\n",
      "('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f4ea841a250>)\n",
      "('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f4ea84e1c20>)\n",
      "('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f4ebc6bead0>)\n",
      "('entity_ruler', <spacy.pipeline.entityruler.EntityRuler object at 0x7f4eac7fac50>)\n"
     ]
    }
   ],
   "source": [
    "reset_pipeline(nlp, [entity_ruler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Baker', 'International', \"'s\"], 'ORG')\n",
      "(['the', 'New', 'York', 'Stock', 'Exchange'], 'ORG')\n"
     ]
    }
   ],
   "source": [
    "text = \"Baker International's shares climbed on the New York Stock Exchange.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "print(*[([t.text for t in e], e.label_) for e in doc.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Bug fix (2021-02-25): added condition `len(ent) > 0` because entity contains just a determiner (which does not make sense in practise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def norm_entities(doc):\n",
    "    ents = []\n",
    "    for ent in doc.ents:\n",
    "        if ent[0].pos_ == \"DET\": # leading article\n",
    "            ent = Span(doc, ent.start+1, ent.end, label=ent.label)\n",
    "        if len(ent) > 0:\n",
    "            if ent[-1].pos_ == \"PART\": # trailing particle like 's\n",
    "                ent = Span(doc, ent.start, ent.end-1, label=ent.label)\n",
    "            if len(ent) > 0:\n",
    "                ents.append(ent)\n",
    "    doc.ents = tuple(ents)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp.add_pipe(norm_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Baker', 'International'], 'ORG')\n",
      "(['New', 'York', 'Stock', 'Exchange'], 'ORG')\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "print(*[([t.text for t in e], e.label_) for e in doc.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Baker International\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "'s shares climbed on the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York Stock Exchange\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# not in book\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Merging Entity Tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Baker International', 'ORG') ('New York Stock Exchange', 'ORG')\n"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import merge_entities\n",
    "if nlp.has_pipe('merge_entities'): ###\n",
    "    _ = nlp.remove_pipe('merge_entities') ###\n",
    "nlp.add_pipe(merge_entities)\n",
    "\n",
    "doc = nlp(text)\n",
    "print(*[(t.text, t.ent_type_) for t in doc if t.ent_type_ != ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing the NER Pipeline on Sample Data (not in book)\n",
    "\n",
    "Take random samples from the text and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: core_web_sm, Language: en\n",
      "('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f4ea841a250>)\n",
      "('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f4ea84e1c20>)\n",
      "('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f4ebc6bead0>)\n",
      "('entity_ruler', <spacy.pipeline.entityruler.EntityRuler object at 0x7f4eac7fac50>)\n",
      "('norm_entities', <function norm_entities at 0x7f4eac9368c0>)\n",
      "('merge_entities', <function merge_entities at 0x7f4ead23aef0>)\n"
     ]
    }
   ],
   "source": [
    "reset_pipeline(nlp, [entity_ruler, norm_entities, merge_entities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Number: 9020\n",
      "Midivest Inc said it acquired all the assets of Business Aviation Inc of Sioux Falls, S.D., for an undisclosed amount of stock. Midivest said it expects to sell 10 to 20 of the renovated Beechcraft planes next year. It said management will also lease these airborne intensive care units to hospitals and government subdivisions through Metropolitan Leasing, a wholly-owned subsidiary of Midivest.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Midivest Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " said it acquired all the assets of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Business Aviation Inc of Sioux Falls\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    S.D.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", for an undisclosed amount of stock. Midivest said it expects to sell \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    10 to 20\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the renovated \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Beechcraft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " planes \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    next year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". It said management will also lease these airborne intensive care units to hospitals and government subdivisions through \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Metropolitan Leasing\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", a wholly-owned subsidiary of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Midivest\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Midivest Inc'], 'ORG')\n",
      "(['Business Aviation Inc of Sioux Falls'], 'ORG')\n",
      "(['S.D.'], 'GPE')\n",
      "(['10 to 20'], 'CARDINAL')\n",
      "(['Beechcraft'], 'ORG')\n",
      "(['next year'], 'DATE')\n",
      "(['Metropolitan Leasing'], 'ORG')\n",
      "(['Midivest'], 'ORG')\n"
     ]
    }
   ],
   "source": [
    "i = df['text'].sample(1).index[0]\n",
    "print(\"Text Number:\", i)\n",
    "\n",
    "text = df['text'].loc[i][:600]\n",
    "text = re.sub(r'\\s+', ' ', text.strip())\n",
    "\n",
    "print(text)\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)\n",
    "print(*[([t.text for t in e], e.label_) for e in doc.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>ent_iob_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baker International</td>\n",
       "      <td>Baker International</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>poss</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York Stock Exchange</td>\n",
       "      <td>New York Stock Exchange</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      text                    lemma    pos   dep ent_type  \\\n",
       "0      Baker International      Baker International  PROPN  poss      ORG   \n",
       "6  New York Stock Exchange  New York Stock Exchange  PROPN  pobj      ORG   \n",
       "\n",
       "  ent_iob_  \n",
       "0        B  \n",
       "6        B  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 500\n",
    "\n",
    "# blueprint function to show tokens with entity attributes\n",
    "display_ner(doc, include_punct=True).query('ent_type != \"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Coreference Resolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blueprint: Using spaCy's Token Extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# not in book, but usefule if you modify the extension\n",
    "from spacy.tokens import Token\n",
    "\n",
    "if Token.has_extension('ref_n'):\n",
    "    _ = Token.remove_extension('ref_n') \n",
    "if Token.has_extension('ref_t'):\n",
    "    _ = Token.remove_extension('ref_t') \n",
    "if Token.has_extension('ref_t_'):\n",
    "    _ = Token.remove_extension('ref_t_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.tokens import Token\n",
    "Token.set_extension('ref_n', default='')\n",
    "Token.set_extension('ref_t', default='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def init_coref(doc):\n",
    "    for e in doc.ents:\n",
    "        if e.label_ in ['ORG', 'GOV', 'PERSON']:\n",
    "            e[0]._.ref_n, e[0]._.ref_t = e.text, e.label_\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blueprint: Alias Resolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transportation Department : ('U.S. Department of Transportation', 'GOV')\n",
      "DOT : ('U.S. Department of Transportation', 'GOV')\n",
      "SEC : ('Securities and Exchange Commission', 'GOV')\n",
      "TWA : ('Trans World Airlines Inc', 'ORG')\n"
     ]
    }
   ],
   "source": [
    "from blueprints.knowledge import alias_lookup\n",
    "\n",
    "for token in ['Transportation Department', 'DOT', 'SEC', 'TWA']:\n",
    "    print(token, ':', alias_lookup[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: core_web_sm, Language: en\n",
      "('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f4ea841a250>)\n",
      "('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f4ea84e1c20>)\n",
      "('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f4ebc6bead0>)\n",
      "('entity_ruler', <spacy.pipeline.entityruler.EntityRuler object at 0x7f4eac7fac50>)\n",
      "('norm_entities', <function norm_entities at 0x7f4eac9368c0>)\n",
      "('merge_entities', <function merge_entities at 0x7f4ead23aef0>)\n",
      "('init_coref', <function init_coref at 0x7f4eac936680>)\n"
     ]
    }
   ],
   "source": [
    "reset_pipeline(nlp, [entity_ruler, norm_entities, merge_entities, init_coref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def alias_resolver(doc):\n",
    "    \"\"\"Lookup aliases and store result in ref_t, ref_n\"\"\"\n",
    "    for ent in doc.ents:\n",
    "        token = ent[0].text\n",
    "        if token in alias_lookup:\n",
    "            a_name, a_type = alias_lookup[token]\n",
    "            ent[0]._.ref_n, ent[0]._.ref_t = a_name, a_type\n",
    "    return propagate_ent_type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def propagate_ent_type(doc):\n",
    "    \"\"\"propagate entity type stored in ref_t\"\"\"\n",
    "    ents = []\n",
    "    for e in doc.ents:\n",
    "        if e[0]._.ref_n != '': # if e is a coreference\n",
    "            e = Span(doc, e.start, e.end, label=e[0]._.ref_t)\n",
    "        ents.append(e)\n",
    "    doc.ents = tuple(ents)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp.add_pipe(alias_resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>ref_n</th>\n",
       "      <th>ref_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trans World Airlines</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Trans World Airlines Inc</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U.S. Department of Transportation</td>\n",
       "      <td>GOV</td>\n",
       "      <td>U.S. Department of Transportation</td>\n",
       "      <td>GOV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Transportation Department</td>\n",
       "      <td>GOV</td>\n",
       "      <td>U.S. Department of Transportation</td>\n",
       "      <td>GOV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TWA</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Trans World Airlines Inc</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text ent_type  \\\n",
       "3                Trans World Airlines      ORG   \n",
       "9   U.S. Department of Transportation      GOV   \n",
       "12          Transportation Department      GOV   \n",
       "18                                TWA      ORG   \n",
       "\n",
       "                                ref_n ref_t  \n",
       "3            Trans World Airlines Inc   ORG  \n",
       "9   U.S. Department of Transportation   GOV  \n",
       "12  U.S. Department of Transportation   GOV  \n",
       "18           Trans World Airlines Inc   ORG  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from blueprints.knowledge import display_ner\n",
    "text = \"\"\"The deal of Trans World Airlines is under investigation by the\n",
    "U.S. Department of Transportation.\n",
    "The Transportation Department will block the deal of TWA.\"\"\"\n",
    "text = re.sub(r'\\s+', ' ', text).strip() ###\n",
    "doc = nlp(text)\n",
    "display_ner(doc).query(\"ref_n != ''\")[['text', 'ent_type', 'ref_n', 'ref_t']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blueprint: Resolving Name Variations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: core_web_sm, Language: en\n",
      "('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f4ea841a250>)\n",
      "('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f4ea84e1c20>)\n",
      "('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f4ebc6bead0>)\n",
      "('entity_ruler', <spacy.pipeline.entityruler.EntityRuler object at 0x7f4eac7fac50>)\n",
      "('norm_entities', <function norm_entities at 0x7f4eac9368c0>)\n",
      "('merge_entities', <function merge_entities at 0x7f4ead23aef0>)\n",
      "('init_coref', <function init_coref at 0x7f4eac936680>)\n",
      "('alias_resolver', <function alias_resolver at 0x7f4eac936b90>)\n"
     ]
    }
   ],
   "source": [
    "reset_pipeline(nlp, [entity_ruler, norm_entities, merge_entities, init_coref, alias_resolver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hughes Tool Co\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " Chairman \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    W.A. Kistler\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said its merger with \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Baker International Corp.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " was still under consideration. We hope to come to a mutual agreement, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kistler\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " said. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Baker\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " will force \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hughes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to complete the merger.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Hughes Tool Co Chairman W.A. Kistler said its merger with \n",
    "Baker International Corp. was still under consideration.\n",
    "We hope to come to a mutual agreement, Kistler said.\n",
    "Baker will force Hughes to complete the merger.\n",
    "\"\"\"\n",
    "text = re.sub(r'\\s+', ' ', text).strip() ### \n",
    "\n",
    "doc = nlp(text) \n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def name_match(m1, m2):\n",
    "    m2 = re.sub(r'[()\\.]', '', m2) # ignore parentheses and dots\n",
    "    m2 = r'\\b' + m2 + r'\\b' # \\b marks word boundary\n",
    "    m2 = re.sub(r'\\s+', r'\\\\b.*\\\\b', m2)\n",
    "    return re.search(m2, m1, flags=re.I) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def name_resolver(doc):\n",
    "    \"\"\"create name-based reference to e1 as primary mention of e2\"\"\"\n",
    "    ents = [e for e in doc.ents if e.label_ in ['ORG', 'PERSON']]\n",
    "    for i, e1 in enumerate(ents):\n",
    "        for e2 in ents[i+1:]:\n",
    "            if name_match(e1[0]._.ref_n, e2[0].text): \n",
    "                e2[0]._.ref_n = e1[0]._.ref_n\n",
    "                e2[0]._.ref_t = e1[0]._.ref_t\n",
    "    return propagate_ent_type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hughes Tool Co\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " Chairman \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    W.A. Kistler\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said its merger with \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Baker International Corp.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " was still under consideration. We hope to come to a mutual agreement, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kistler\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Baker\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " will force \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hughes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to complete the merger.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.add_pipe(name_resolver)\n",
    "\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>ref_n</th>\n",
       "      <th>ref_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hughes Tool Co</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Hughes Tool Co</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W.A. Kistler</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>W.A. Kistler</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baker International Corp.</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Baker International Corp.</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kistler</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>W.A. Kistler</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Baker</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Baker International Corp.</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hughes</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Hughes Tool Co</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text ent_type                      ref_n   ref_t\n",
       "0              Hughes Tool Co      ORG             Hughes Tool Co     ORG\n",
       "2                W.A. Kistler   PERSON               W.A. Kistler  PERSON\n",
       "7   Baker International Corp.      ORG  Baker International Corp.     ORG\n",
       "22                    Kistler   PERSON               W.A. Kistler  PERSON\n",
       "25                      Baker      ORG  Baker International Corp.     ORG\n",
       "28                     Hughes      ORG             Hughes Tool Co     ORG"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_ner(doc).query(\"ref_n != ''\")[['text', 'ent_type', 'ref_n', 'ref_t']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing Name Coreference Resolution Sample Data (not in book)\n",
    "\n",
    "Take random samples from the text and display the result. You may find examples where the resolution is not working correctly. We have put the emphasis on the simplicity of rules, so there will be cases in which they don't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: core_web_sm, Language: en\n",
      "('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f4ea841a250>)\n",
      "('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f4ea84e1c20>)\n",
      "('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f4ebc6bead0>)\n",
      "('entity_ruler', <spacy.pipeline.entityruler.EntityRuler object at 0x7f4eac7fac50>)\n",
      "('norm_entities', <function norm_entities at 0x7f4eac9368c0>)\n",
      "('merge_entities', <function merge_entities at 0x7f4ead23aef0>)\n",
      "('init_coref', <function init_coref at 0x7f4eac936680>)\n",
      "('alias_resolver', <function alias_resolver at 0x7f4eac936b90>)\n",
      "('name_resolver', <function name_resolver at 0x7f4ea84e7c20>)\n"
     ]
    }
   ],
   "source": [
    "reset_pipeline(nlp, [entity_ruler, norm_entities, merge_entities, init_coref, alias_resolver, name_resolver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Number: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Computer Terminal Systems Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " said it has completed the sale of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    200,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " shares of its common stock, and warrants to acquire an \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    additional one million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " shares, to \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sedio N.V.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lugano\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Switzerland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    50,000 dollars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ". The company said the warrants are exercisable for \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    five years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " at a purchase price of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    .125 dollars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " per share. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Computer Terminal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " said \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sedio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " also has the right to buy additional shares and increase its total holdings \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    up to 40 %\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " of the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Computer Terminal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "'s outstanding common stock under certain circumstances involving change of control at the company. The company said if the conditions occur the warrants would be exercisable at a price equal to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    75 %\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " of its common stock's market price at the time, not to exceed \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1.50 dollars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " per share. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Computer Terminal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " also said it sold the technolgy rights to its \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Dot Matrix\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " impact technology, including any future improvements, to \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Woodco Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Houston\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", Tex. for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    200,000 dollars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ". But, it said it would continue to be the exclusive worldwide licensee of the technology for \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Woodco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". The company said the moves were part of its reorganization plan and would help pay current operation costs and ensure product delivery. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Computer Terminal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " makes computer generated labels, forms, tags and ticket printers and terminals.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>ent_iob_</th>\n",
       "      <th>ref_n</th>\n",
       "      <th>ref_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer Terminal Systems Inc</td>\n",
       "      <td>Computer Terminal Systems Inc</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B</td>\n",
       "      <td>Computer Terminal Systems Inc</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sedio N.V.</td>\n",
       "      <td>Sedio N.V.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B</td>\n",
       "      <td>Sedio N.V.</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Computer Terminal</td>\n",
       "      <td>Computer Terminal</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B</td>\n",
       "      <td>Computer Terminal Systems Inc</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Sedio</td>\n",
       "      <td>sedio</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B</td>\n",
       "      <td>Sedio N.V.</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Computer Terminal</td>\n",
       "      <td>Computer Terminal</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>poss</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B</td>\n",
       "      <td>Computer Terminal Systems Inc</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Computer Terminal</td>\n",
       "      <td>Computer Terminal</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B</td>\n",
       "      <td>Computer Terminal Systems Inc</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Woodco Inc</td>\n",
       "      <td>Woodco Inc</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B</td>\n",
       "      <td>Woodco Inc</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Woodco</td>\n",
       "      <td>Woodco</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B</td>\n",
       "      <td>Woodco Inc</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Computer Terminal</td>\n",
       "      <td>computer terminal</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B</td>\n",
       "      <td>Computer Terminal Systems Inc</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text                          lemma    pos  \\\n",
       "0    Computer Terminal Systems Inc  Computer Terminal Systems Inc  PROPN   \n",
       "24                      Sedio N.V.                     Sedio N.V.  PROPN   \n",
       "50               Computer Terminal              Computer Terminal  PROPN   \n",
       "52                           Sedio                          sedio   NOUN   \n",
       "69               Computer Terminal              Computer Terminal  PROPN   \n",
       "121              Computer Terminal              Computer Terminal  PROPN   \n",
       "141                     Woodco Inc                     Woodco Inc  PROPN   \n",
       "167                         Woodco                         Woodco  PROPN   \n",
       "192              Computer Terminal              computer terminal   NOUN   \n",
       "\n",
       "       dep ent_type ent_iob_                          ref_n ref_t  \n",
       "0    nsubj      ORG        B  Computer Terminal Systems Inc   ORG  \n",
       "24    pobj      ORG        B                     Sedio N.V.   ORG  \n",
       "50   nsubj      ORG        B  Computer Terminal Systems Inc   ORG  \n",
       "52   nsubj      ORG        B                     Sedio N.V.   ORG  \n",
       "69    poss      ORG        B  Computer Terminal Systems Inc   ORG  \n",
       "121  nsubj      ORG        B  Computer Terminal Systems Inc   ORG  \n",
       "141   pobj      ORG        B                     Woodco Inc   ORG  \n",
       "167   pobj      ORG        B                     Woodco Inc   ORG  \n",
       "192  nsubj      ORG        B  Computer Terminal Systems Inc   ORG  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not in the book:\n",
    "# pick random examples to test the string matching\n",
    "\n",
    "i = df['text'].sample(1).index[0]\n",
    "i = 10\n",
    "print(\"Text Number:\", i)\n",
    "\n",
    "text = df['text'].loc[i]#[:300]\n",
    "# print(text)\n",
    "\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)\n",
    "\n",
    "display_ner(doc).query(\"ref_n != ''\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blueprint: Anaphora Resolution with NeuralCoref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Hughes Tool Co said its merger with Baker\n",
    "was still under consideration. Hughes had a board meeting today.\n",
    "W.A. Kistler mentioned that the company hopes for a mutual agreement.\n",
    "He is reasonably confident.\"\"\"\n",
    "text = re.sub(r'\\s+', ' ', text).strip() ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: core_web_sm, Language: en\n",
      "('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f4ea841a250>)\n",
      "('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f4ea84e1c20>)\n",
      "('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f4ebc6bead0>)\n",
      "('entity_ruler', <spacy.pipeline.entityruler.EntityRuler object at 0x7f4eac7fac50>)\n",
      "('norm_entities', <function norm_entities at 0x7f4eac9368c0>)\n",
      "('merge_entities', <function merge_entities at 0x7f4ead23aef0>)\n",
      "('init_coref', <function init_coref at 0x7f4eac936680>)\n",
      "('alias_resolver', <function alias_resolver at 0x7f4eac936b90>)\n",
      "('name_resolver', <function name_resolver at 0x7f4ea84e7c20>)\n"
     ]
    }
   ],
   "source": [
    "reset_pipeline(nlp, [entity_ruler, norm_entities, merge_entities, \n",
    "                     init_coref, alias_resolver, name_resolver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralcoref import NeuralCoref\n",
    "neural_coref = NeuralCoref(nlp.vocab, greedyness=0.45)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "nlp.add_pipe(neural_coref, name='neural_coref')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "print(*doc._.coref_clusters, sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Not in the book: Try the visualization of NeuralCoref!\n",
    "\n",
    "https://huggingface.co/coref/?text=Hughes%20Tool%20Co%20said%20its%20merger%20with%20Baker%20was%20still%20under%20consideration.%20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def anaphor_coref(doc):\n",
    "    \"\"\"anaphora resolution\"\"\"\n",
    "    for token in doc:\n",
    "        # if token is coref and not already dereferenced\n",
    "        if token._.in_coref and token._.ref_n == '': \n",
    "            ref_span = token._.coref_clusters[0].main # get referred span\n",
    "            if len(ref_span) <= 3: # consider only short spans\n",
    "                for ref in ref_span: # find first dereferenced entity\n",
    "                    if ref._.ref_n != '':\n",
    "                        token._.ref_n = ref._.ref_n\n",
    "                        token._.ref_t = ref._.ref_t\n",
    "                        break\n",
    "    return doc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if nlp.has_pipe('anaphor_coref'): ###\n",
    "    nlp.remove_pipe('anaphor_coref') ###\n",
    "nlp.add_pipe(anaphor_coref)\n",
    "doc = nlp(text)\n",
    "display_ner(doc).query(\"ref_n != ''\") \\\n",
    "  [['text', 'ent_type', 'main_coref', 'ref_n', 'ref_t']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Name Normalization\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def strip_legal_suffix(text):\n",
    "    return re.sub(r'(\\s+and)?(\\s+|\\b(Co|Corp|Inc|Plc|Ltd)\\b\\.?)*$', '', text)\n",
    "\n",
    "print(strip_legal_suffix('Hughes Tool Co'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def norm_names(doc):\n",
    "    for t in doc:\n",
    "        if t._.ref_n != '' and t._.ref_t in ['ORG']:\n",
    "            t._.ref_n = strip_legal_suffix(t._.ref_n)\n",
    "            if t._.ref_n == '':\n",
    "                t._.ref_t = ''\n",
    "                \n",
    "    return doc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp.add_pipe(norm_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entity Linking\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing Coreference Resolution (not in book)\n",
    "\n",
    "Not in the book, but a good demonstration of what works good and what doesn't work, yet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# recreate pipeline\n",
    "reset_pipeline(nlp, [entity_ruler, norm_entities, merge_entities, \n",
    "                     init_coref, alias_resolver, name_resolver, anaphor_coref, norm_names])\n",
    "                     #neural_coref"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# recreate pipeline\n",
    "reset_pipeline(nlp, [entity_ruler, norm_entities, merge_entities, \n",
    "                     init_coref, alias_resolver, name_resolver, anaphor_coref, norm_names])\n",
    "                     #neural_coref"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: core_web_sm, Language: en\n",
      "('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f4ea841a250>)\n",
      "('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f4ea84e1c20>)\n",
      "('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f4ebc6bead0>)\n",
      "('entity_ruler', <spacy.pipeline.entityruler.EntityRuler object at 0x7f4eac7fac50>)\n",
      "('norm_entities', <function norm_entities at 0x7f4eac9368c0>)\n",
      "('merge_entities', <function merge_entities at 0x7f4ead23aef0>)\n",
      "('init_coref', <function init_coref at 0x7f4eac936680>)\n",
      "('alias_resolver', <function alias_resolver at 0x7f4eac936b90>)\n",
      "('name_resolver', <function name_resolver at 0x7f4ea84e7c20>)\n",
      "('anaphor_coref', <function anaphor_coref at 0x7f4eaba80170>)\n",
      "('norm_names', <function norm_names at 0x7f4eabc15830>)\n"
     ]
    }
   ],
   "source": [
    "# pick random examples and test\n",
    "\n",
    "i = df['text'].sample(1).index[0]\n",
    "i = 2948 # 1862, 1836,2948,7650,3013,2950,3095\n",
    "print(\"Text Number:\", i)\n",
    "\n",
    "text = df['text'].loc[i][:500]\n",
    "print(text)\n",
    "\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)\n",
    "\n",
    "display_ner(doc).query(\"ref_n != ''\")[['text', 'ent_type', 'main_coref', 'ref_n', 'ref_t']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Number: 2948\n",
      "The U.S. Department of Transportation said it dismissed on technical grounds an application by Trans World Airlines Inc for DOT approval for it to take control of USAir Group. The DOT added, however, that TWA was free to refile when it could put together an application for control that met the agency's procedural requirements. The DOT acted shortly after the U.S. Department of Justice disclosed that it supported dismissal of the TWA application. It was not immediately clear what impact the denia\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "[E046] Can't retrieve unregistered extension attribute 'in_coref'. Did you forget to call the `set_extension` method?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53547/2786167618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjupyter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/miniconda3/envs/bertopic/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_53547/3635087964.py\u001b[0m in \u001b[0;36manaphor_coref\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# if token is coref and not already dereferenced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_coref\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref_n\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mref_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoref_clusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[0;31m# get referred span\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_span\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# consider only short spans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/miniconda3/envs/bertopic/lib/python3.7/site-packages/spacy/tokens/underscore.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE046\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: [E046] Can't retrieve unregistered extension attribute 'in_coref'. Did you forget to call the `set_extension` method?"
     ]
    }
   ],
   "source": [
    "# pick random examples and test\n",
    "\n",
    "i = df['text'].sample(1).index[0]\n",
    "i = 2948 # 1862, 1836,2948,7650,3013,2950,3095\n",
    "print(\"Text Number:\", i)\n",
    "\n",
    "text = df['text'].loc[i][:500]\n",
    "print(text)\n",
    "\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)\n",
    "\n",
    "display_ner(doc).query(\"ref_n != ''\")[['text', 'ent_type', 'main_coref', 'ref_n', 'ref_t']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Blueprint: Creating a Cooccurence Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Largest connected component of the cooccurrence graph generated from the Reuters corpus**  \n",
    "The visualization was prepared with the help of [Gephi](https://gephi.org/).\n",
    "<img src=\"figures/cooc.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extracting Cooccurrences from a Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def extract_coocs(doc, include_types):\n",
    "    ents = set([(e[0]._.ref_n, e[0]._.ref_t) \n",
    "                for e in doc.ents if e[0]._.ref_t in include_types])\n",
    "    yield from combinations(sorted(ents), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reset_pipeline(nlp, [entity_ruler, norm_entities, merge_entities, \n",
    "                     init_coref, alias_resolver, name_resolver,\n",
    "                     neural_coref, anaphor_coref, norm_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "batches = math.ceil(len(df)/batch_size) ###\n",
    "\n",
    "coocs = []\n",
    "for i in tqdm(range(0, len(df), batch_size), total=batches):\n",
    "    docs = nlp.pipe(df['text'][i:i+batch_size],\n",
    "                    disable=['neural_coref', 'anaphor_coref'])\n",
    "    for j, doc in enumerate(docs):\n",
    "        coocs.extend([(df.index[i+j], *c) \n",
    "                      for c in extract_coocs(doc, ['ORG', 'GOV'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(*coocs[:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "coocs = [([id], *e1, *e2) for (id, e1, e2) in coocs]\n",
    "cooc_df = pd.DataFrame.from_records(coocs, \n",
    "             columns=('article_id', 'ent1', 'type1', 'ent2', 'type2')) \n",
    "cooc_df = cooc_df.groupby(['ent1', 'type1', 'ent2', 'type2'])['article_id'] \\\n",
    "                 .agg(['count', 'sum']) \\\n",
    "                 .rename(columns={'count': 'freq', 'sum': 'articles'}) \\\n",
    "                 .reset_index().sort_values('freq', ascending=False)\n",
    "cooc_df['articles'] = cooc_df['articles'].map(\n",
    "                        lambda lst: ','.join([str(a) for a in lst[:5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cooc_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualizing the Graph with Gephi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graph = nx.from_pandas_edgelist(\n",
    "           cooc_df[['ent1', 'ent2', 'articles', 'freq']] \\\n",
    "           .query('freq > 3').rename(columns={'freq': 'weight'}),\n",
    "           source='ent1', target='ent2', edge_attr=True)\n",
    "\n",
    "nx.readwrite.write_gexf(graph, 'cooc.gexf', encoding='utf-8', \n",
    "                        prettyprint=True, version='1.2draft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualizing the Graph with NetworkX (not in book)\n",
    "\n",
    "We can also use NetworkX for drawing, it's just not that nice. By executing the code below you will see more nodes than in the book, where we manually removed several nodes for the sake of clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# identify the greatest component (connected subgraph)\n",
    "# and plot only that one\n",
    "giant_component = sorted(nx.connected_components(graph), key=len, reverse=True)\n",
    "graph = graph.subgraph(giant_component[0])\n",
    "\n",
    "pos = nx.kamada_kawai_layout(graph, weight='weight')\n",
    "# pos = nx.fruchterman_reingold_layout(graph, weight='weight')\n",
    "# pos = nx.circular_layout(graph)\n",
    "\n",
    "_ = plt.figure(figsize=(20, 20))\n",
    "nx.draw(graph, pos, \n",
    "        node_size=1000, \n",
    "        node_color='skyblue',\n",
    "        alpha=0.8,\n",
    "        with_labels = True)\n",
    "plt.title('Graph Visualization', size=15)\n",
    "\n",
    "for (node1,node2,data) in graph.edges(data=True):\n",
    "    width = data['weight'] \n",
    "    _ = nx.draw_networkx_edges(graph,pos,\n",
    "                               edgelist=[(node1, node2)],\n",
    "                               width=width,\n",
    "                               edge_color='#505050',\n",
    "                               alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blueprint: Identifying Acronyms (not in book)\n",
    "\n",
    "It is very easy to generate a very good list of suggestions for acronyms if you search for frequent cooccurrences of acronyms. \n",
    "\n",
    "To find possible acronyms in the cooccurrence data frame, we look for all tuples that have an acronym (all capital letters) either as source or as target. As additional conditions, we require that the first letter in both is the same and the combination exists more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reset_pipeline(nlp, [entity_ruler, norm_entities, merge_entities, \n",
    "                     init_coref, name_resolver, norm_names]) # no alias resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "batches = math.ceil(len(df)/batch_size) ###\n",
    "\n",
    "coocs = []\n",
    "for i in tqdm(range(0, len(df), batch_size), total=batches):\n",
    "    docs = nlp.pipe(df['text'][i:i+batch_size])\n",
    "    for j, doc in enumerate(docs):\n",
    "        coocs.extend([(df.index[i+j], *c) for c in extract_coocs(doc, ['ORG', 'GOV'])])\n",
    "\n",
    "coocs = [([id], *e1, *e2) for (id, e1, e2) in coocs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cooc_df = pd.DataFrame.from_records(coocs, \n",
    "             columns=('article_id', 'ent1', 'type1', 'ent2', 'type2')) \n",
    "cooc_df = cooc_df.groupby(['ent1', 'ent2'])['article_id'] \\\n",
    "                 .agg(['count']).rename(columns={'count': 'freq'}) \\\n",
    "                 .reset_index().sort_values('freq', ascending=False)\n",
    "\n",
    "acro_pattern = (cooc_df['ent1'].str.isupper() | cooc_df['ent2'].str.isupper()) & \\\n",
    "               (cooc_df['ent1'].str[:1] == cooc_df['ent2'].str[:1]) & \\\n",
    "               (cooc_df['freq'] > 1)\n",
    "\n",
    "print(len(cooc_df[acro_pattern]))\n",
    "cooc_df[acro_pattern][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For our corpus, this yields about 40 potential acronyms.\n",
    "\n",
    "We save them to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# export to csv\n",
    "cooc_df[acro_pattern][['ent1', 'ent2']] \\\n",
    "  .sort_values(['ent1', 'ent2']) \\\n",
    "  .to_csv('possible_acronyms.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This file has to be curated manually. After cleaning, we load the remaining acronyms and convert them to a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# curate manually the csv\n",
    "acro_df = pd.read_csv('possible_acronyms.txt')\n",
    "acro_df.set_index('ent1')['ent2'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We took this list, and curated it to create a dictionary that maps acronyms to their long names. It is  provided in the blueprints package for this chapter and part of `alias_lookup`. Here are some example entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from blueprints.knowledge import _acronyms\n",
    "\n",
    "for acro in ['TWA', 'UCPB', 'SEC', 'DOT']:\n",
    "    print(acro, ' --> ', alias_lookup[acro])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Relation Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blueprint: Relation Extraction by Phrase Matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# use large model, otherwise the examples look different!\n",
    "# to make it work on Colab, we need to import the model directly\n",
    "# usually you would use nlp = spacy.load('en_core_web_lg') \n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "\n",
    "# need to re-create the entity ruler after reloading nlp\n",
    "# because new entity type 'GOV' needs to be added to nlp.vocab\n",
    "entity_ruler = EntityRuler(nlp, patterns=patterns, overwrite_ents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# recreate pipeline\n",
    "reset_pipeline(nlp, [entity_ruler, norm_entities, merge_entities, \n",
    "                     init_coref, alias_resolver, name_resolver, norm_names,\n",
    "                     neural_coref, anaphor_coref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Fujitsu plans to acquire 80% of Fairchild Corp, an industrial unit\n",
    "of Schlumberger.\"\"\"\n",
    "text = re.sub('\\s+', ' ', text).strip() ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "acq_synonyms = ['acquire', 'buy', 'purchase']\n",
    "pattern = [{'_': {'ref_t': 'ORG'}}, # subject\n",
    "           {'_': {'ref_t': {'NOT_IN': ['ORG']}}, 'OP': '*'},\n",
    "           {'POS': 'VERB', 'LEMMA': {'IN': acq_synonyms}},\n",
    "           {'_': {'ref_t': {'NOT_IN': ['ORG']}}, 'OP': '*'},\n",
    "           {'_': {'ref_t': 'ORG'}}] # object\n",
    "matcher.add('acquires', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subs_synonyms = ['subsidiary', 'unit']\n",
    "pattern = [{'_': {'ref_t': 'ORG'}}, # subject\n",
    "           {'_': {'ref_t': {'NOT_IN': ['ORG']}}, \n",
    "            'POS': {'NOT_IN': ['VERB']}, 'OP': '*'},\n",
    "           {'LOWER': {'IN': subs_synonyms}}, {'TEXT': 'of'},\n",
    "           {'_': {'ref_t': {'NOT_IN': ['ORG']}}, \n",
    "            'POS': {'NOT_IN': ['VERB']}, 'OP': '*'},\n",
    "           {'_': {'ref_t': 'ORG'}}] # object\n",
    "matcher.add('subsidiary-of', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_rel_match(doc, matcher):\n",
    "    for sent in doc.sents:\n",
    "        for match_id, start, end in matcher(sent):\n",
    "            span = sent[start:end]  # matched span\n",
    "            pred = nlp.vocab.strings[match_id] # rule name\n",
    "            subj, obj = span[0], span[-1]\n",
    "            if pred.startswith('rev-'): # reversed relation\n",
    "                subj, obj = obj, subj\n",
    "                pred = pred[4:]\n",
    "            yield ((subj._.ref_n, subj._.ref_t), pred, \n",
    "                   (obj._.ref_n, obj._.ref_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pattern = [{'_': {'ref_t': 'ORG'}}, # subject\n",
    "           {'LOWER': {'IN': subs_synonyms}}, # predicate\n",
    "           {'_': {'ref_t': 'ORG'}}] # object\n",
    "matcher.add('rev-subsidiary-of', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Fujitsu plans to acquire 80% of Fairchild Corp, an industrial unit \n",
    "of Schlumberger. The Schlumberger unit Fairchild Corp received an offer.\"\"\"\n",
    "text = re.sub('\\s+', ' ', text) ###\n",
    "doc = nlp(text)\n",
    "print(*extract_rel_match(doc, matcher), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Fairchild Corp was acquired by Fujitsu.\"\n",
    "print(*extract_rel_match(nlp(text), matcher), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Fujitsu, a competitor of NEC, acquired Fairchild Corp.\"\n",
    "print(*extract_rel_match(nlp(text), matcher), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if matcher.has_key(\"acquires\"): \n",
    "    matcher.remove(\"acquires\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blueprint: Relation Extraction using Dependency Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# recreate pipeline\n",
    "reset_pipeline(nlp, [norm_entities, merge_entities, \n",
    "                     init_coref, alias_resolver, name_resolver, norm_names,\n",
    "                     neural_coref, anaphor_coref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Fujitsu, a competitor of NEC, acquired Fairchild Corp.\"\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='dep', jupyter=True, \n",
    "                options={'compact': False, 'distance': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Fairchild Corp was acquired by Fujitsu.\"\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'compact': False, 'distance': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here is the longer part of the code, that was skipped in the book.\n",
    "\n",
    "# Actually we search for the shortest path between the\n",
    "# subject running through our predicate (verb) to the object.\n",
    "# subject and object are organizations in our examples.\n",
    "\n",
    "# Here are the three helper functions omitted in the book:\n",
    "# - bfs: breadth first searching the closest subject/object \n",
    "# - is_passive: checks if noun or verb is in passive form\n",
    "# - find_subj: searches left part of tree for subject\n",
    "# - find_obj: searches right part of tree for object\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "def bfs(root, ent_type, deps, first_dep_only=False):\n",
    "    \"\"\"Return first child of root (included) that matches\n",
    "    ent_type and dependency list by breadth first search.\n",
    "    Search stops after first dependency match if first_dep_only\n",
    "    (used for subject search - do not \"jump\" over subjects)\"\"\"\n",
    "    to_visit = deque([root]) # queue for bfs\n",
    "\n",
    "    while len(to_visit) > 0:\n",
    "        child = to_visit.popleft()\n",
    "        # print(\"child\", child, child.dep_)\n",
    "        if child.dep_ in deps:\n",
    "            if child._.ref_t == ent_type:\n",
    "                return child\n",
    "            elif first_dep_only: # first match (subjects)\n",
    "                return None\n",
    "        elif child.dep_ == 'compound' and \\\n",
    "             child.head.dep_ in deps and \\\n",
    "             child._.ref_t == ent_type: # check if contained in compound\n",
    "            return child\n",
    "        to_visit.extend(list(child.children))\n",
    "    return None\n",
    "\n",
    "def is_passive(token):\n",
    "    if token.dep_.endswith('pass'): # noun\n",
    "        return True\n",
    "    for left in token.lefts: # verb\n",
    "        if left.dep_ == 'auxpass':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_subj(pred, ent_type, passive):\n",
    "    \"\"\"Find closest subject in predicates left subtree or\n",
    "    predicates parent's left subtree (recursive).\n",
    "    Has a filter on organizations.\"\"\"\n",
    "    for left in pred.lefts:\n",
    "        if passive: # if pred is passive, search for passive subject\n",
    "            subj = bfs(left, ent_type, ['nsubjpass', 'nsubj:pass'], True)\n",
    "        else:\n",
    "            subj = bfs(left, ent_type, ['nsubj'], True)\n",
    "        if subj is not None: # found it!\n",
    "            return subj\n",
    "    if pred.head != pred and not is_passive(pred): \n",
    "        return find_subj(pred.head, ent_type, passive) # climb up left subtree\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def find_obj(pred, ent_type, excl_prepos):\n",
    "    \"\"\"Find closest object in predicates right subtree.\n",
    "    Skip prepositional objects if the preposition is in exclude list.\n",
    "    Has a filter on organizations.\"\"\"\n",
    "    for right in pred.rights:\n",
    "        obj = bfs(right, ent_type, ['dobj', 'pobj', 'iobj', 'obj', 'obl'])\n",
    "        if obj is not None:\n",
    "            if obj.dep_ == 'pobj' and obj.head.lemma_.lower() in excl_prepos: # check preposition\n",
    "                continue\n",
    "            return obj\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_rel_dep(doc, pred_name, pred_synonyms, excl_prepos=[]):\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB' and token.lemma_ in pred_synonyms:\n",
    "            pred = token\n",
    "            passive = is_passive(pred)\n",
    "            subj = find_subj(pred, 'ORG', passive)\n",
    "            if subj is not None:\n",
    "                obj = find_obj(pred, 'ORG', excl_prepos)\n",
    "                if obj is not None:\n",
    "                    if passive: # switch roles\n",
    "                        obj, subj = subj, obj\n",
    "                    yield ((subj._.ref_n, subj._.ref_t), pred_name, \n",
    "                           (obj._.ref_n, obj._.ref_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Fujitsu said that Schlumberger Ltd has arranged \n",
    "to sell its stake in Fairchild Inc.\"\"\"\n",
    "doc = nlp(text)\n",
    "print(*extract_rel_dep(doc, 'sells', ['sell']), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Schlumberger Ltd has arranged to sell to Fujitsu its stake in Fairchild Inc.\"\n",
    "doc = nlp(text)\n",
    "print(*extract_rel_dep(doc, 'sells', ['sell']), sep='\\n')\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'compact': False, 'distance': 80})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"A:\", *extract_rel_dep(doc, 'sells', ['sell']))\n",
    "print(\"B:\", *extract_rel_dep(doc, 'sells', ['sell'], ['to', 'from']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "texts = [ \n",
    "     \"Fairchild Corp was bought by Fujitsu.\", # 1\n",
    "     \"Fujitsu, a competitor of NEC Co, acquired Fairchild Inc.\", # 2\n",
    "     \"Fujitsu is expanding.\" + \n",
    "     \"The company made an offer to acquire 80% of Fairchild Inc.\", # 3\n",
    "     \"Fujitsu plans to acquire 80% of Fairchild Corp.\", # 4\n",
    "     \"Fujitsu plans not to acquire Fairchild Corp.\", # 5\n",
    "     \"The competition forced Fujitsu to aquire Fairchild Corp.\" # 6\n",
    "]\n",
    "\n",
    "acq_synonyms = ['acquire', 'buy', 'purchase']\n",
    "for i, text in enumerate(texts):\n",
    "    doc = nlp(text)\n",
    "    rels = extract_rel_dep(doc, 'acquires', acq_synonyms, ['to', 'from'])\n",
    "    print(f'{i+1}:', *rels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Creating the Knowledge Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**On Colab**: Choose \"Runtime\"&rarr;\"Change Runtime Type\"&rarr;\"GPU\" to benefit from the GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if spacy.prefer_gpu():\n",
    "    print(\"Working on GPU.\")\n",
    "else:\n",
    "    print(\"No GPU found, working on CPU.\")\n",
    "\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# need to re-create the entity ruler after reloading nlp\n",
    "# because new entity type 'GOV' needs to be added to nlp.vocab\n",
    "entity_ruler = EntityRuler(nlp, patterns=patterns, overwrite_ents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipes = [entity_ruler, norm_entities, merge_entities,\n",
    "         init_coref, alias_resolver, name_resolver, \n",
    "         neural_coref, anaphor_coref, norm_names]\n",
    "for pipe in pipes:\n",
    "    nlp.add_pipe(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# recreate matcher - same definition as above for these rules\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "subs_synonyms = ['subsidiary', 'unit']\n",
    "pattern = [{'_': {'ref_t': 'ORG'}}, # subject\n",
    "           {'_': {'ref_t': {'NOT_IN': ['ORG']}}, 'POS': {'NOT_IN': ['VERB']}, 'OP': '*'},\n",
    "           {'LOWER': {'IN': subs_synonyms}}, # predicate\n",
    "           {'TEXT': 'of'},\n",
    "           {'_': {'ref_t': {'NOT_IN': ['ORG']}}, 'POS': {'NOT_IN': ['VERB']}, 'OP': '*'},\n",
    "           {'_': {'ref_t': 'ORG'}}] # object\n",
    "matcher.add('subsidiary-of', None, pattern)\n",
    "\n",
    "pattern = [{'_': {'ref_t': 'ORG'}}, # subject\n",
    "           {'POS': 'PART', 'OP': '?'},\n",
    "           {'LOWER': {'IN': subs_synonyms}}, # predicate\n",
    "           {'_': {'ref_t': 'ORG'}}] # object\n",
    "matcher.add('rev-subsidiary-of', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ceo_synonyms = ['chairman', 'president', 'director', 'ceo', 'executive']\n",
    "pattern = [{'ENT_TYPE': 'PERSON'},\n",
    "           {'ENT_TYPE': {'NOT_IN': ['ORG', 'PERSON']}, 'OP': '*'}, \n",
    "           {'LOWER': {'IN': ceo_synonyms}}, {'TEXT': 'of'},\n",
    "           {'ENT_TYPE': {'NOT_IN': ['ORG', 'PERSON']}, 'OP': '*'}, \n",
    "           {'ENT_TYPE': 'ORG'}] \n",
    "matcher.add('executive-of', None, pattern)\n",
    "\n",
    "pattern = [{'ENT_TYPE': 'ORG'}, \n",
    "           {'LOWER': {'IN': ceo_synonyms}},\n",
    "           {'ENT_TYPE': 'PERSON'}] \n",
    "matcher.add('rev-executive-of', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_rels(doc):\n",
    "    yield from extract_rel_match(doc, matcher)\n",
    "    yield from extract_rel_dep(doc, 'acquires', acq_synonyms, ['to', 'from'])\n",
    "    yield from extract_rel_dep(doc, 'sells', ['sell'], ['to', 'from'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing Relationship Extraction (not in book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Allied-Signal Inc and Schlumberger Ltd jointly announced \n",
    "that Schlumberger had acquired Allied-Signal's unit Neptune International. \n",
    "\"\"\"\n",
    "#text = df.text.loc[19975]\n",
    "\n",
    "text = re.sub(r'\\s+', ' ', text).strip()\n",
    "print(*textwrap.wrap(text, 100), sep='\\n')\n",
    "print()\n",
    "doc = nlp(text, disable='entity_ruler')\n",
    "#displacy.render(doc, style='ent')\n",
    "print(*extract_rels(doc), sep='\\n')\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'compact': False, 'distance': 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extraction of Entities and Relations and Creation of Gephi-File (not in book)\n",
    "\n",
    "Batch-processing for entity extraction with subsequent relation extraction. Takes about 5 minutes,  80% of runtime for NeuralCoref."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "batch_size = 20\n",
    "batches = ceil(len(df) / batch_size) ###\n",
    "\n",
    "rels = []\n",
    "for i in tqdm(range(0, len(df), batch_size), total=batches):\n",
    "    docs = nlp.pipe(df['text'][i:i+batch_size])\n",
    "    for j, doc in enumerate(docs):\n",
    "        rels.extend([(df.index[i+j], *r) for r in extract_rels(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creation of the relation data frame including final curation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# unpack subject and object \n",
    "rels = [(a_id, *subj, pred, *obj) for (a_id, subj, pred, obj) in rels]\n",
    "\n",
    "# create data frame\n",
    "rel_df = pd.DataFrame.from_records(rels, columns=('article_id', 'subj', 'subj_type', 'pred', 'obj', 'obj_type'))\n",
    "\n",
    "# false positives: subject cannot be object\n",
    "rel_df = rel_df.query('subj != obj')\n",
    "\n",
    "# filter entities that were not correctly detected\n",
    "# tokenizer produces \"-owned XYZ company\"\n",
    "rel_df = rel_df[~rel_df['subj'].str.startswith('-own')]\n",
    "rel_df = rel_df[~rel_df['obj'].str.startswith('-own')]\n",
    "\n",
    "# drop duplicate relations (within an article)\n",
    "rel_df = rel_df.drop_duplicates()\n",
    "\n",
    "# aggregate to produce one record per relation\n",
    "rel_df['article_id'] = rel_df['article_id'].map(lambda a: [a])\n",
    "rel_df = rel_df.groupby(['subj', 'subj_type', 'pred', 'obj', 'obj_type'])['article_id'] \\\n",
    "                 .agg(['count', 'sum']) \\\n",
    "                 .rename(columns={'count': 'freq', 'sum': 'articles'}) \\\n",
    "                 .reset_index().sort_values('freq', ascending=False)\n",
    "\n",
    "rel_df['articles'] = rel_df['articles'].map(lambda lst: ','.join(list(set([str(a) for a in lst]))))\n",
    "rel_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# some statitics\n",
    "rel_df['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# try searching for a specific entity\n",
    "search = \"Trans World\"\n",
    "rel_df[(rel_df.subj.str.lower().str.contains(search.lower()) | \n",
    "        rel_df.obj.str.lower().str.contains(search.lower()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# in fact, TWA acquires and sells parts of USAir according to the messages\n",
    "# look at a specific article\n",
    "text = df['text'][9487]\n",
    "print(*textwrap.wrap(text, 80), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To create the NetworkX graph be careful: We need a `MultiDiGraph` here, a directed graph allowing multiple edges between two nodes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx import MultiDiGraph\n",
    "\n",
    "graph = MultiDiGraph()\n",
    "for i, row in rel_df.iterrows():\n",
    "    graph.add_node(row['subj'], Type=row['subj_type'])\n",
    "    graph.add_node(row['obj'], Type=row['obj_type'])\n",
    "    _ = graph.add_edge(row['subj'], row['obj'], \n",
    "                   Articles=row['articles'], Rel=row['pred'])\n",
    "   \n",
    "nx.readwrite.write_gexf(graph, 'knowledge_graph.gexf', encoding='utf-8', \n",
    "                         prettyprint=True, version='1.2draft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Choose merge strategy \"last\" when you load the data into Gephi, as relations with highest counts come last in the gexf file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Book section continues ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Don't Blindly Trust the Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Closing Remarks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Further Reading\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "712px",
    "left": "100px",
    "top": "110.8px",
    "width": "199.985px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "472.4px",
    "left": "933.2px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}